#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
G√©n√©rateur de N-grams pour le clavier cr√©ole - Potomitan‚Ñ¢
Cr√©e des bigrammes et trigrammes √† partir des textes cr√©oles

Usage:
    1. Cr√©er un fichier .env avec: HF_TOKEN=hf_xxxxxxxxxxxxxxxxx
    2. Ex√©cuter: python GenererNgrams.py
    
    Le script chargera automatiquement le token depuis .env
"""

import json
import re
from collections import Counter, defaultdict
import itertools
from datasets import load_dataset
from dotenv import load_dotenv
import os

def charger_textes_kreyol(hf_token=None):
    """
    Charge tous les textes cr√©oles disponibles
    
    Args:
        hf_token (str, optional): Token Hugging Face pour l'authentification
    """
    textes = []
    
    # 1. Essayer de charger le dataset depuis Hugging Face
    try:
        print("üîÑ T√©l√©chargement du dataset depuis Hugging Face...")
        if hf_token:
            print("üîë Utilisation du token Hugging Face fourni")
            ds = load_dataset("POTOMITAN/PawolKreyol-gfc", token=hf_token)
        else:
            print("üìÇ Acc√®s public au dataset")
            ds = load_dataset("POTOMITAN/PawolKreyol-gfc")
        
        for item in ds['train']:
            if item.get('Texte') and item['Texte'].strip():
                textes.append(item['Texte'].strip())
        
        print(f"‚úÖ Charg√© {len(textes)} textes depuis Hugging Face Dataset")
        return textes
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors du t√©l√©chargement depuis Hugging Face: {e}")
        if not hf_token:
            print("üí° Conseil: Essayez avec un token HF si le dataset est priv√©")
        print("üîÑ Tentative de chargement depuis le fichier local...")
    
    # 2. Fallback : charger depuis le fichier local
    try:
        with open("PawolKreyol/Textes_kreyol.json", 'r', encoding='utf-8') as f:
            data = json.load(f)
            for item in data:
                if item.get('Texte') and item['Texte'].strip():
                    textes.append(item['Texte'].strip())
        
        print(f"‚úÖ Charg√© {len(textes)} textes depuis Textes_kreyol.json (fallback)")
        return textes
        
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement du fichier local: {e}")
        print("‚ùå Aucune source de donn√©es disponible!")
        return []

def nettoyer_et_tokeniser(texte):
    """Nettoie le texte et le tokenise en mots"""
    # Nettoyer le texte
    texte = texte.lower()
    
    # Garder uniquement les mots cr√©oles (avec accents et apostrophes)
    pattern = r"[a-zA-Z√≤√©√®√π√†√¢√™√Æ√¥√ª√ß√Ä√â√à√ô√í]+(?:['-][a-zA-Z√≤√©√®√π√†√¢√™√Æ√¥√ª√ß√Ä√â√à√ô√í]+)*"
    mots = re.findall(pattern, texte)
    
    # Filtrer les mots trop courts
    mots_valides = [mot for mot in mots if len(mot) >= 2]
    
    return mots_valides

def generer_bigrammes(mots):
    """G√©n√®re des bigrammes (s√©quences de 2 mots)"""
    bigrammes = []
    for i in range(len(mots) - 1):
        bigramme = (mots[i], mots[i + 1])
        bigrammes.append(bigramme)
    return bigrammes

def generer_trigrammes(mots):
    """G√©n√®re des trigrammes (s√©quences de 3 mots)"""
    trigrammes = []
    for i in range(len(mots) - 2):
        trigramme = (mots[i], mots[i + 1], mots[i + 2])
        trigrammes.append(trigramme)
    return trigrammes

def creer_modele_ngrams(textes):
    """Cr√©e le mod√®le de N-grams depuis les textes"""
    print("üîÑ Cr√©ation du mod√®le de N-grams...")
    
    # Compteurs pour les n-grams
    unigrammes_count = Counter()  # Nouveau: compteur pour unigrammes
    bigrammes_count = Counter()
    trigrammes_count = Counter()
    mots_suivants = defaultdict(Counter)  # mot -> {mot_suivant: freq}
    
    total_unigrammes = 0
    total_bigrammes = 0
    total_trigrammes = 0
    
    for texte in textes:
        if not texte:
            continue
            
        mots = nettoyer_et_tokeniser(texte)
        if len(mots) < 1:
            continue
        
        # G√©n√©rer unigrammes (mots individuels)
        unigrammes_count.update(mots)
        total_unigrammes += len(mots)
            
        if len(mots) < 2:
            continue
            
        # G√©n√©rer bigrammes
        bigrammes = generer_bigrammes(mots)
        bigrammes_count.update(bigrammes)
        total_bigrammes += len(bigrammes)
        
        # Cr√©er le mapping mot -> mots suivants
        for mot1, mot2 in bigrammes:
            mots_suivants[mot1][mot2] += 1
        
        # G√©n√©rer trigrammes si assez de mots
        if len(mots) >= 3:
            trigrammes = generer_trigrammes(mots)
            trigrammes_count.update(trigrammes)
            total_trigrammes += len(trigrammes)
    
    print(f"üìä Statistiques:")
    print(f"   - Unigrammes uniques: {len(unigrammes_count)}")
    print(f"   - Bigrammes uniques: {len(bigrammes_count)}")
    print(f"   - Trigrammes uniques: {len(trigrammes_count)}")
    print(f"   - Total unigrammes: {total_unigrammes}")
    print(f"   - Total bigrammes: {total_bigrammes}")
    print(f"   - Total trigrammes: {total_trigrammes}")
    
    return unigrammes_count, bigrammes_count, trigrammes_count, mots_suivants

def convertir_en_probabilites(mots_suivants):
    """Convertit les compteurs en probabilit√©s"""
    modele_probabilites = {}
    
    for mot_precedent, compteur_suivants in mots_suivants.items():
        total = sum(compteur_suivants.values())
        if total > 0:
            probabilites = {}
            for mot_suivant, count in compteur_suivants.items():
                probabilites[mot_suivant] = count / total
            modele_probabilites[mot_precedent] = probabilites
    
    return modele_probabilites

def sauvegarder_modele_ngrams(unigrammes, bigrammes, trigrammes, mots_suivants):
    """Sauvegarde le mod√®le de N-grams pour Android"""
    
    # 1. Mod√®le de pr√©diction simple : mot -> mots suivants avec probabilit√©s
    modele_predictions = convertir_en_probabilites(mots_suivants)
    
    # 2. Top unigrammes (mots les plus fr√©quents)
    top_unigrammes = {}
    for mot, count in unigrammes.most_common(500):
        top_unigrammes[mot] = count
    
    # 3. Top bigrammes pour validation (convertir tuples en strings)
    top_bigrammes = {}
    for (mot1, mot2), count in bigrammes.most_common(1000):
        key = f"{mot1} {mot2}"  # Convertir tuple en string
        top_bigrammes[key] = count
    
    # 4. Format pour Android
    modele_android = {
        "version": "1.1",
        "type": "ngram_model",
        "branding": "Potomitan‚Ñ¢",
        "predictions": {},
        "top_unigrammes": top_unigrammes,
        "top_bigrammes": top_bigrammes,
        "stats": {
            "total_unigrammes": len(unigrammes),
            "total_bigrammes": len(bigrammes),
            "total_trigrammes": len(trigrammes),
            "mots_avec_predictions": len(modele_predictions)
        }
    }
    
    # 5. Convertir le mod√®le de pr√©dictions en format compact
    for mot, probabilites in modele_predictions.items():
        # Garder seulement les 5 mots suivants les plus probables
        top_predictions = sorted(probabilites.items(), key=lambda x: x[1], reverse=True)[:5]
        if top_predictions:
            modele_android["predictions"][mot] = [
                {"word": mot_suivant, "prob": round(prob, 3)} 
                for mot_suivant, prob in top_predictions
            ]
    
    # 6. Sauvegarder pour Android
    chemin_ngrams = "../android_keyboard/app/src/main/assets/creole_ngrams.json"
    
    try:
        # Cr√©er le dossier assets s'il n'existe pas
        import os
        os.makedirs(os.path.dirname(chemin_ngrams), exist_ok=True)
        
        with open(chemin_ngrams, 'w', encoding='utf-8') as f:
            json.dump(modele_android, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ Mod√®le N-grams sauvegard√©: {chemin_ngrams}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la sauvegarde dans {chemin_ngrams}: {e}")
        # Fallback: sauvegarder dans le dossier courant
        chemin_local = "creole_ngrams.json"
        with open(chemin_local, 'w', encoding='utf-8') as f:
            json.dump(modele_android, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ Mod√®le N-grams sauvegard√© (fallback): {chemin_local}")
        chemin_ngrams = chemin_local
    
    return len(modele_android["predictions"])

def afficher_exemples_predictions(unigrammes, mots_suivants):
    """Affiche des exemples de pr√©dictions"""
    print("\nüéØ Exemples de pr√©dictions N-grams:")
    
    # Afficher les 10 unigrammes les plus fr√©quents
    print("\nüìä Top 10 mots les plus fr√©quents (unigrammes):")
    for mot, count in unigrammes.most_common(10):
        print(f"   '{mot}' ‚Üí {count} occurrences")
    
    # Mots cr√©oles courants pour exemples de bigrammes
    print("\nüîó Exemples de pr√©dictions bigrammes:")
    mots_exemples = ["an", "ka", "t√©", "nou", "yo", "pou", "s√©", "i"]
    
    for mot in mots_exemples:
        if mot in mots_suivants:
            top_suivants = mots_suivants[mot].most_common(3)
            predictions = [f"{suivant}({count})" for suivant, count in top_suivants]
            print(f"   '{mot}' ‚Üí {', '.join(predictions)}")

def main():
    print("=== G√©n√©ration des N-grams pour le clavier cr√©ole - Potomitan‚Ñ¢ ===")
    
    # 1. Charger les variables d'environnement depuis .env
    load_dotenv()
    
    # 2. R√©cup√©rer le token Hugging Face
    hf_token = os.getenv('HF_TOKEN')
    
    if hf_token:
        print(f"üîë Token Hugging Face trouv√© dans .env")
    else:
        print("‚ÑπÔ∏è Aucun token trouv√© dans .env - tentative d'acc√®s public")
        print("üí° Pour utiliser un token: ajoutez HF_TOKEN=<votre_token> dans le fichier .env")
    
    # 3. Charger les textes
    print("üìö Chargement des textes cr√©oles...")
    textes = charger_textes_kreyol(hf_token)
    print(f"Textes charg√©s: {len(textes)}")
    
    if not textes:
        print("‚ùå Aucun texte trouv√© ! V√©rifiez les chemins de fichiers.")
        return
    
    # 4. Cr√©er le mod√®le N-grams
    unigrammes, bigrammes, trigrammes, mots_suivants = creer_modele_ngrams(textes)
    
    # 5. Afficher des exemples
    afficher_exemples_predictions(unigrammes, mots_suivants)
    
    # 6. Sauvegarder le mod√®le
    nb_predictions = sauvegarder_modele_ngrams(unigrammes, bigrammes, trigrammes, mots_suivants)
    
    print(f"\nüéâ Mod√®le N-grams cr√©√© avec succ√®s !")
    print(f"üìà {nb_predictions} mots avec pr√©dictions disponibles")
    print(f"üéØ Pr√™t pour l'int√©gration Android !")

if __name__ == "__main__":
    main()
